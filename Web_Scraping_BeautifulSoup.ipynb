{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT-1 WEB SCRAPING SOLUTIONS_BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\abhimanyu\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\abhimanyu\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\abhimanyu\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\abhimanyu\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhimanyu\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\abhimanyu\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\abhimanyu\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\abhimanyu\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4\n",
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Write a python program to display all the header tags from 'https://en.wikipedia.org/wiki/Main_Page'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Main Page', \"From today's featured article\", 'Did you know\\xa0...', 'In the news', 'On this day', \"Today's featured picture\", 'Other areas of Wikipedia', \"Wikipedia's sister projects\", 'Wikipedia languages', 'Navigation menu', 'Personal tools', 'Namespaces', 'Variantsexpandedcollapsed', 'Views', 'Moreexpandedcollapsed', 'Search', 'Navigation', 'Contribute', 'Tools', 'Print/export', 'In other projects', 'Languages']\n"
     ]
    }
   ],
   "source": [
    "# download the page content:\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#creating empty list\n",
    "header = []\n",
    "\n",
    "#scraping header\n",
    "for i in soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    header.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://www.imdb.com/chart/top/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250 250\n"
     ]
    }
   ],
   "source": [
    "# download the page content:\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#creating empty lists\n",
    "name = []\n",
    "rating = []\n",
    "year = []\n",
    "\n",
    "#scraping name and year\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    name.append(i.text.split('\\n')[2])\n",
    "    year.append(i.text.split('\\n')[3])\n",
    "    \n",
    "#scraping ratings\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    rating.append(i.text.split('\\n')[1])\n",
    "    \n",
    "print(len(name),len(rating),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Name of a movie</th>\n",
       "      <th>Rating (out of 10)</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.1</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Jagten</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Requiem for a Dream</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1952)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ranking                              Name of a movie Rating (out of 10)  \\\n",
       "0         1                     The Shawshank Redemption                9.2   \n",
       "1         2                                The Godfather                9.1   \n",
       "2         3                       The Godfather: Part II                9.0   \n",
       "3         4                              The Dark Knight                9.0   \n",
       "4         5                                 12 Angry Men                8.9   \n",
       "..      ...                                          ...                ...   \n",
       "95       96                                       Jagten                8.3   \n",
       "96       97                          Requiem for a Dream                8.3   \n",
       "97       98                          Singin' in the Rain                8.3   \n",
       "98       99                           North by Northwest                8.3   \n",
       "99      100        Eternal Sunshine of the Spotless Mind                8.3   \n",
       "\n",
       "   Year of release  \n",
       "0           (1994)  \n",
       "1           (1972)  \n",
       "2           (1974)  \n",
       "3           (2008)  \n",
       "4           (1957)  \n",
       "..             ...  \n",
       "95          (2012)  \n",
       "96          (2000)  \n",
       "97          (1952)  \n",
       "98          (1959)  \n",
       "99          (2004)  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating database of top 100 movies on the basis of IMDB rating\n",
    "top_100 = pd.DataFrame({\"Ranking\":range(1,101),\"Name of a movie\":name[:100],\"Rating (out of 10)\":rating[:100],\"Year of release\":year[:100]})\n",
    "top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=461131e5-5af0-4e50-bee2-223fad1e00ca&pf_rd_r=W99JK9KBV75GSJ99BFE2&pf_rd_s=center-1&pf_rd_t=60601&pf_rd_i=india.toprated&ref_=fea_india_ss_toprated_india_tr_india250_sm')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250 250\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "name = []\n",
    "rating = []\n",
    "year = []\n",
    "\n",
    "#scraping name and year\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    name.append(i.text.split('\\n')[2])\n",
    "    year.append(i.text.split('\\n')[3])\n",
    "\n",
    "#scraping ratings\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    rating.append(i.text.split('\\n')[1])\n",
    "    \n",
    "print(len(name),len(rating),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Name of a movie</th>\n",
       "      <th>Rating (out of 10)</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Munna Bhai M.B.B.S.</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Sarfarosh</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Queen</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Roja</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ranking                 Name of a movie Rating (out of 10) Year of release\n",
       "0         1                        Jai Bhim                8.5          (2021)\n",
       "1         2               Pariyerum Perumal                8.5          (2018)\n",
       "2         3                         Nayakan                8.5          (1987)\n",
       "3         4                      Anbe Sivam                8.5          (2003)\n",
       "4         5               C/o Kancharapalem                8.5          (2018)\n",
       "..      ...                             ...                ...             ...\n",
       "95       96             Munna Bhai M.B.B.S.                8.1          (2003)\n",
       "96       97                       Sarfarosh                8.1          (1999)\n",
       "97       98                           Queen                8.1          (2013)\n",
       "98       99                            Roja                8.1          (1992)\n",
       "99      100        Uri: The Surgical Strike                8.1          (2019)\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating database of top 100 Indian movies on the basis of IMDB rating\n",
    "top_100 = pd.DataFrame({\"Ranking\":range(1,101),\"Name of a movie\":name[:100],\"Rating (out of 10)\":rating[:100],\"Year of release\":year[:100]})\n",
    "top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Write a python program to scrape product name, price and discounts from 'https://meesho.com/bags-ladies/pl/p7vbp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "name = []\n",
    "price = []\n",
    "discount = []\n",
    "\n",
    "#scraping name\n",
    "for i in soup.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\"):\n",
    "    name.append(i.text)\n",
    "\n",
    "#scraping price\n",
    "for i in soup.find_all('div',class_=\"Card__BaseCard-sc-b3n78k-0 iLPHgK NewProductCard__PriceRow-sc-j0e7tu-5 eyya-Dr NewProductCard__PriceRow-sc-j0e7tu-5 eyya-Dr\"):\n",
    "    price.append(i.text.split(\"₹\")[1])\n",
    "\n",
    "#scraping discount\n",
    "for i in soup.find_all('span',class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\"):\n",
    "    discount.append(i.text)\n",
    "\n",
    "\n",
    "print(len(name),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>price in ₹</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elite Fancy Women Handbags</td>\n",
       "      <td>103</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moon Mart Latest girls and kids Handbag</td>\n",
       "      <td>215</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ravishing Attractive Women Handbags</td>\n",
       "      <td>383</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ravishing Fancy Women Handbags</td>\n",
       "      <td>7</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elite Alluring Women Handbags</td>\n",
       "      <td>383</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jeanspatterncaplady Handbags</td>\n",
       "      <td>105</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jute Bags</td>\n",
       "      <td>434</td>\n",
       "      <td>19% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benicia Giraffe Print Poly Canvas Tote Bag wit...</td>\n",
       "      <td>200</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hend bags</td>\n",
       "      <td>285</td>\n",
       "      <td>26% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Handbags</td>\n",
       "      <td>100</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SHA-LUXE Handbag</td>\n",
       "      <td>305</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Handbags</td>\n",
       "      <td>105</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Voguish Attractive Women Handbags</td>\n",
       "      <td>383</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Elite Fancy Women Handbags</td>\n",
       "      <td>323</td>\n",
       "      <td>24% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ladies handbags</td>\n",
       "      <td>245</td>\n",
       "      <td>29% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Voguish Stylish Women Handbags</td>\n",
       "      <td>12</td>\n",
       "      <td>29% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Women PINK  Shoulder Bag - Extra Spacious</td>\n",
       "      <td>199</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>canvasgreenleafy</td>\n",
       "      <td>105</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Classic Stylish Women Handbags</td>\n",
       "      <td>9</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jutefloralbag</td>\n",
       "      <td>103</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product Name price in ₹ discount\n",
       "0                          Elite Fancy Women Handbags        103  30% off\n",
       "1             Moon Mart Latest girls and kids Handbag        215  30% off\n",
       "2                 Ravishing Attractive Women Handbags        383  21% off\n",
       "3                      Ravishing Fancy Women Handbags          7  30% off\n",
       "4                       Elite Alluring Women Handbags        383  21% off\n",
       "5                       jeanspatterncaplady Handbags         105  30% off\n",
       "6                                           Jute Bags        434  19% off\n",
       "7   Benicia Giraffe Print Poly Canvas Tote Bag wit...        200  30% off\n",
       "8                                          Hend bags         285  26% off\n",
       "9                                            Handbags        100  30% off\n",
       "10                                   SHA-LUXE Handbag        305  25% off\n",
       "11                                          Handbags         105  30% off\n",
       "12                  Voguish Attractive Women Handbags        383  21% off\n",
       "13                         Elite Fancy Women Handbags        323  24% off\n",
       "14                                    ladies handbags        245  29% off\n",
       "15                     Voguish Stylish Women Handbags         12  29% off\n",
       "16          Women PINK  Shoulder Bag - Extra Spacious        199  30% off\n",
       "17                                   canvasgreenleafy        105  30% off\n",
       "18                     Classic Stylish Women Handbags          9  25% off\n",
       "19                                      jutefloralbag        103  30% off"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame \n",
    "df = pd.DataFrame({\"Product Name\":name, \"price in ₹\":price, \"discount\":discount})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Write a python program to scrape cricket rankings from 'icc-cricket.com' You have to scrape:\n",
    "* a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "* b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "* c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank          Team Matches Points Rating\n",
      "0     1   New Zealand      32  3,793    119\n",
      "1     2       England      28  3,244    116\n",
      "2     3     Australia      32  3,624    113\n",
      "3     4         India      25  2,459     98\n",
      "4     5  South Africa      27  2,524     93\n",
      "5     6      Pakistan      30  2,740     91\n",
      "6     7    Bangladesh      30  2,523     84\n",
      "7     8   West Indies      32  2,657     83\n",
      "8     9     Sri Lanka      17  1,054     62\n",
      "9    10   Afghanistan       7    336     48\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "team = []\n",
    "matches = []\n",
    "points = []\n",
    "rating = []\n",
    "\n",
    "#scraping team\n",
    "for i in soup.find_all('span', class_=\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "\n",
    "#scraping matches played by team \n",
    "for i in list(soup.find_all('td',attrs={'table-body__cell u-center-text'}))[::2]:\n",
    "    matches.append(i.text)\n",
    "\n",
    "#scraping points\n",
    "for i in list(soup.find_all('td',attrs={'table-body__cell u-center-text'}))[1::2]:\n",
    "    points.append(i.text)\n",
    "\n",
    "#scraping ratings\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "\n",
    "# Creating data frame \n",
    "df = pd.DataFrame({\"rank\":range(1,11),\"Team\":team[:10],\"Matches\":matches[:10] ,\"Points\":points[:10] ,\"Rating\":rating[:10]})\n",
    "df.to_csv('top_10_odi_teams.csv',index = False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "Rank = range(1,11)\n",
    "#creating empty lists\n",
    "name = []\n",
    "team = []\n",
    "rating = []\n",
    "\n",
    "# scraping names\n",
    "for i in soup.find('div',class_=\"rankings-block__banner--name\"):\n",
    "    name.append(i)                 \n",
    "for i in soup.find_all('td',attrs=\"table-body__cell name\")[:9]:\n",
    "    name.append(i.text.split(\"\\n\")[1])\n",
    "\n",
    "# scraping team name\n",
    "team1 = (soup.find('div',attrs={\"rankings-block__banner--nationality\"}).text)\n",
    "team.append((team1[2:5]).replace('\\n',''))\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\")[:9]:\n",
    "    team.append(i.text.replace('\\n',''))\n",
    "    \n",
    "#scraping rating\n",
    "rating.append((soup.find('div',attrs=\"rankings-block__banner--rating\")).text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\")[:9]:\n",
    "    rating.append(i.text)\n",
    "    \n",
    "    \n",
    "print(len(name),len(team),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name of Batsmen Team Rating(Points)\n",
      "1        Babar Azam  PAK            873\n",
      "2       Virat Kohli  IND            844\n",
      "3      Rohit Sharma  IND            813\n",
      "4       Ross Taylor   NZ            801\n",
      "5       Aaron Finch  AUS            779\n",
      "6    Jonny Bairstow  ENG            775\n",
      "7      David Warner  AUS            762\n",
      "8         Shai Hope   WI            758\n",
      "9   Kane Williamson   NZ            754\n",
      "10  Quinton de Kock   SA            743\n"
     ]
    }
   ],
   "source": [
    "# Creating data frame \n",
    "df = pd.DataFrame({\"Name of Batsmen\":name,\"Team\":team,\"Rating(Points)\":rating}, index = Rank)\n",
    "df.to_csv('top_10_odi_batsmen.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "rank = range(1,11)\n",
    "name = []\n",
    "team = []\n",
    "rating = []\n",
    "\n",
    "# scraping names\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name\")[1:2]:\n",
    "    name.append(i.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\")[9:18]:\n",
    "    name.append(i.text.replace('\\n',''))\n",
    "    \n",
    "#scraping team\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\")[1:2]:\n",
    "    team.append(i.text.replace(\"\\n\",\"\").split()[0])\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\")[9:18]:\n",
    "    team.append(i.text.replace('\\n',''))\n",
    "    \n",
    "#scraping ratings\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\")[1:2]:\n",
    "    rating.append(i.text.replace(\"\\n\",\"\").split()[1])\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\")[9:18]:\n",
    "    rating.append(i.text)\n",
    "    \n",
    "print(len(name),len(team),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name of baller Team ratings\n",
      "1        Trent Boult   NZ     737\n",
      "2     Josh Hazlewood  AUS     709\n",
      "3   Mujeeb Ur Rahman  AFG     708\n",
      "4       Chris Woakes  ENG     700\n",
      "5       Mehedi Hasan  BAN     692\n",
      "6         Matt Henry   NZ     691\n",
      "7     Jasprit Bumrah  IND     679\n",
      "8     Mitchell Starc  AUS     652\n",
      "9    Shakib Al Hasan  BAN     650\n",
      "10     Kagiso Rabada   SA     643 \n",
      " \n",
      " (row,column) : (10, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creating data frame \n",
    "df = pd.DataFrame({\"Name of baller\":name,\"Team\":team,\"ratings\":rating},index=rank)\n",
    "df.to_csv('top_10_odi_bowlers.csv')\n",
    "print(df,\"\\n\",\"\\n\",\"(row,column) :\",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "* a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "* b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "* c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#download the page content.\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#creating empty lists\n",
    "rank = range(1,11)\n",
    "team = []\n",
    "match = []\n",
    "point = []\n",
    "rating = []\n",
    "\n",
    "#scraping top 10 team data\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\")[:10]:\n",
    "    team.append(i.text)\n",
    "\n",
    "#scraping matches played by teams\n",
    "for i in soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    match.append(i.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\")[:18:2]:\n",
    "    match.append(i.text)\n",
    "    \n",
    "#scraping points\n",
    "for i in soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    point.append(i.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\")[1:19:2]:\n",
    "    point.append(i.text)\n",
    "\n",
    "#scraping rating\n",
    "for i in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\").replace(\" \",\"\"))\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\")[:9]:\n",
    "    rating.append(i.text)\n",
    "    \n",
    "print(len(team),len(point),len(match),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Team Matches Points Rating\n",
      "1      Australia      17  2,746    162\n",
      "2   South Africa      19  2,307    121\n",
      "3        England      18  2,148    119\n",
      "4          India      17  1,899    112\n",
      "5     Bangladesh       5    475     95\n",
      "6    New Zealand      19  1,668     88\n",
      "7    West Indies      19  1,658     87\n",
      "8       Pakistan      18  1,226     68\n",
      "9        Ireland       5    240     48\n",
      "10     Sri Lanka       5    233     47\n"
     ]
    }
   ],
   "source": [
    "# Creating data frame \n",
    "df = pd.DataFrame({\"Team\":team,\"Matches\":match,\"Points\":point,\"Rating\":rating},index=rank)\n",
    "df.to_csv('top_10_odi_teams_womens.csv',index = False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "Rank = range(1,11)\n",
    "name = []\n",
    "team = []\n",
    "rating = []\n",
    "\n",
    "#scraping names\n",
    "for i in soup.find('div',class_=\"rankings-block__banner--name\"):\n",
    "    name.append(i)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\")[:9]:\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "#scraping team\n",
    "team1 = (soup.find('div',attrs={\"rankings-block__banner--nationality\"}).text)\n",
    "team.append((team1[2:5]).replace('\\n',''))   \n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\")[:9]:\n",
    "    team.append(i.text.replace('\\n',''))\n",
    "\n",
    "#scraping rating\n",
    "rating.append((soup.find('div',attrs=\"rankings-block__banner--rating\")).text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\")[:9]:\n",
    "    rating.append(i.text)\n",
    "\n",
    "    \n",
    "print(len(name),len(team),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Name of Player Team Rating\n",
      "1         Lizelle Lee   SA    761\n",
      "2        Alyssa Healy  AUS    750\n",
      "3         Mithali Raj  IND    738\n",
      "4      Tammy Beaumont  ENG    728\n",
      "5   Amy Satterthwaite   NZ    717\n",
      "6     Smriti Mandhana  IND    710\n",
      "7         Meg Lanning  AUS    699\n",
      "8         Beth Mooney  AUS    690\n",
      "9     Stafanie Taylor   WI    676\n",
      "10     Heather Knight  ENG    674\n"
     ]
    }
   ],
   "source": [
    "# Creating data frame \n",
    "df = pd.DataFrame({\"Name of Player\":name,\"Team\":team,\"Rating\":rating}, index = Rank)\n",
    "df.to_csv('top_10_odi_batsmen_Women.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "Rank = range(1,11)\n",
    "name = []\n",
    "team = []\n",
    "rating = []\n",
    "\n",
    "#scraping names\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name\")[2:]:\n",
    "    name.append(i.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\")[18:27]:\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "#scraping team\n",
    "for i in soup.find_all('div',attrs=\"rankings-block__banner--nationality\")[2:]:\n",
    "    team.append(i.text.replace(\"\\n\",\"\").replace(\" \",\"\")[:2])\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\")[18:27]:\n",
    "    team.append(i.text.replace('\\n',''))\n",
    "\n",
    "#scraping rating\n",
    "for i in soup.find_all('div',attrs=\"rankings-block__banner--rating\")[2:]:\n",
    "    rating.append(i.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\")[18:27]:\n",
    "    rating.append(i.text)\n",
    "\n",
    "print(len(name),len(team),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name of Player Team Rating\n",
      "1     Marizanne Kapp   SA    384\n",
      "2     Natalie Sciver  ENG    372\n",
      "3       Ellyse Perry  AUS    365\n",
      "4    Stafanie Taylor   WI    319\n",
      "5      Deepti Sharma  IND    299\n",
      "6   Ashleigh Gardner  AUS    275\n",
      "7   Dane van Niekerk   SA    274\n",
      "8    Hayley Matthews   WI    272\n",
      "9      Jess Jonassen  AUS    272\n",
      "10   Katherine Brunt  ENG    272\n"
     ]
    }
   ],
   "source": [
    "# Creating data frame \n",
    "df = pd.DataFrame({\"Name of Player\":name,\"Team\":team,\"Rating\":rating}, index = Rank)\n",
    "df.to_csv('top_10_odi_all_rounder_Women.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://coreyms.com/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "heading = []\n",
    "date = []\n",
    "content = []\n",
    "vid = []\n",
    "\n",
    "#scraping the headings\n",
    "for i in soup.find_all('h2',class_=\"entry-title\"):\n",
    "    heading.append(i.text)\n",
    "\n",
    "#Scraping date of publish\n",
    "for i in soup.find_all('time',class_=\"entry-time\"):\n",
    "    date.append(i.text)\n",
    "\n",
    "#sraping the content\n",
    "for i in soup.find_all('div',class_=\"entry-content\"):\n",
    "    content.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "#Sraping the video link\n",
    "for i in soup.find_all('iframe',class_=\"youtube-player\"):\n",
    "    vid.append(i['src'])\n",
    "vid.insert(4,'Nan') #as there is no video link for heading no. 5\n",
    "\n",
    "print(len(heading),len(date),len(content),len(vid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading</th>\n",
       "      <th>Date of publish</th>\n",
       "      <th>Content</th>\n",
       "      <th>Video Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>November 19, 2019</td>\n",
       "      <td>In this video, we will be learning how to crea...</td>\n",
       "      <td>https://www.youtube.com/embed/z0gguhEmWiY?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>October 17, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>https://www.youtube.com/embed/_P7X8tMplsw?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>https://www.youtube.com/embed/fKl2JW_qrso?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>September 12, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>https://www.youtube.com/embed/IEEhzQoKtQU?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>September 3, 2019</td>\n",
       "      <td>Hey everyone. I wanted to give you an update o...</td>\n",
       "      <td>Nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Quick Tip: The Difference Between “==” ...</td>\n",
       "      <td>August 6, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/mO_dS3rXDIs?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Tutorial: Calling External Commands Usi...</td>\n",
       "      <td>July 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/2Fp1N6dof0Y?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Visual Studio Code (Windows) – Setting up a Py...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/-nh9rCzPJ20?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visual Studio Code (Mac) – Setting up a Python...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/06I63_p-2A4?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarifying the Issues with Mutable Default Arg...</td>\n",
       "      <td>April 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/_JGmemuINww?vers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Heading     Date of publish  \\\n",
       "0  Python Tutorial: Zip Files – Creating and Extr...   November 19, 2019   \n",
       "1  Python Data Science Tutorial: Analyzing the 20...    October 17, 2019   \n",
       "2  Python Multiprocessing Tutorial: Run Code in P...  September 21, 2019   \n",
       "3  Python Threading Tutorial: Run Code Concurrent...  September 12, 2019   \n",
       "4                                Update (2019-09-03)   September 3, 2019   \n",
       "5  Python Quick Tip: The Difference Between “==” ...      August 6, 2019   \n",
       "6  Python Tutorial: Calling External Commands Usi...       July 24, 2019   \n",
       "7  Visual Studio Code (Windows) – Setting up a Py...         May 1, 2019   \n",
       "8  Visual Studio Code (Mac) – Setting up a Python...         May 1, 2019   \n",
       "9  Clarifying the Issues with Mutable Default Arg...      April 24, 2019   \n",
       "\n",
       "                                             Content  \\\n",
       "0  In this video, we will be learning how to crea...   \n",
       "1  In this Python Programming video, we will be l...   \n",
       "2  In this Python Programming video, we will be l...   \n",
       "3  In this Python Programming video, we will be l...   \n",
       "4  Hey everyone. I wanted to give you an update o...   \n",
       "5  In this Python Programming Tutorial, we will b...   \n",
       "6  In this Python Programming Tutorial, we will b...   \n",
       "7  In this Python Programming Tutorial, we will b...   \n",
       "8  In this Python Programming Tutorial, we will b...   \n",
       "9  In this Python Programming Tutorial, we will b...   \n",
       "\n",
       "                                          Video Link  \n",
       "0  https://www.youtube.com/embed/z0gguhEmWiY?vers...  \n",
       "1  https://www.youtube.com/embed/_P7X8tMplsw?vers...  \n",
       "2  https://www.youtube.com/embed/fKl2JW_qrso?vers...  \n",
       "3  https://www.youtube.com/embed/IEEhzQoKtQU?vers...  \n",
       "4                                                Nan  \n",
       "5  https://www.youtube.com/embed/mO_dS3rXDIs?vers...  \n",
       "6  https://www.youtube.com/embed/2Fp1N6dof0Y?vers...  \n",
       "7  https://www.youtube.com/embed/-nh9rCzPJ20?vers...  \n",
       "8  https://www.youtube.com/embed/06I63_p-2A4?vers...  \n",
       "9  https://www.youtube.com/embed/_JGmemuINww?vers...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame \n",
    "df = pd.DataFrame({\"Heading\":heading,\"Date of publish\":date,\"Content\":content,\"Video Link\":vid})\n",
    "df.to_csv(\"details of all the posts from coreyms.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Write a python program to scrape house details from mentioned URL. It should include house title, location, area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, Rajaji Nagar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://www.nobroker.in/property/rent/bangalore/multiple?searchParam=W3sibGF0IjoxMi45NzgzNjkyLCJsb24iOjc3LjY0MDgzNTYsInBsYWNlSWQiOiJDaElKa1FOM0dLUVdyanNSTmhCUUpyaEdEN1UiLCJwbGFjZU5hbWUiOiJJbmRpcmFuYWdhciJ9LHsibGF0IjoxMi45MzA3NzM1LCJsb24iOjc3LjU4MzgzMDIsInBsYWNlSWQiOiJDaElKMmRkbFo1Z1ZyanNSaDFCT0FhZi1vcnMiLCJwbGFjZU5hbWUiOiJKYXlhbmFnYXIifSx7ImxhdCI6MTIuOTk4MTczMiwibG9uIjo3Ny41NTMwNDQ1OTk5OTk5OSwicGxhY2VJZCI6IkNoSUp4Zlc0RFBNOXJqc1JLc05URy01cF9RUSIsInBsYWNlTmFtZSI6IlJhamFqaW5hZ2FyIn1d&radius=2.0&sharedAccomodation=0&city=bangalore&locality=Indiranagar,&locality=Jayanagar,&locality=Rajajinagar')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "title =[]\n",
    "location = []\n",
    "area = []\n",
    "price = []\n",
    "emi = []\n",
    "\n",
    "#scraping house title\n",
    "for i in soup.find_all('a',class_=\"nb__U5JyW\"):\n",
    "    title.append(i.text)\n",
    "\n",
    "#scraping locations\n",
    "for i in soup.find_all('div',class_=\"nb__nXU01\"):\n",
    "    location.append(i.text)\n",
    "\n",
    "#scraping area\n",
    "for i in soup.find_all('div',class_=\"nb__FfHqA\"):\n",
    "    area.append(i.text)\n",
    "\n",
    "#scraping price\n",
    "for i in soup.find_all('div',class_=\"font-semi-bold heading-6\")[1::3]:\n",
    "    price.append(i.text)\n",
    "\n",
    "#Scraping emi\n",
    "for i in soup.find_all('div',class_=\"font-semi-bold heading-6\")[2::3]:\n",
    "    emi.append(i.text)\n",
    "    \n",
    "print(len(title),len(location),len(area),len(price),len(emi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>Price(Deposite)</th>\n",
       "      <th>EMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 BHK Flat  For Rent  In Stanalone Building In...</td>\n",
       "      <td>no 715 2 nd main d block rajaji nagar 2nd stat...</td>\n",
       "      <td>1,400 sqft</td>\n",
       "      <td>₹1,00,000</td>\n",
       "      <td>₹ 17,000 +₹ 500 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 RK Flat  For Rent  In Rajajinagar</td>\n",
       "      <td>Standalone Building, 2nd Block, near O.G. Vari...</td>\n",
       "      <td>250 sqft</td>\n",
       "      <td>₹40,000</td>\n",
       "      <td>₹ 6,000 +₹ 500 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 BHK Apartment  For Rent  In Santa Clara Apar...</td>\n",
       "      <td>Santa Clara Apartments  3rd Rd Cross Rd, 5T Bl...</td>\n",
       "      <td>1,400 sqft</td>\n",
       "      <td>₹1,80,000</td>\n",
       "      <td>₹ 27,000 +₹ 3,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House, D'mart ,RBI Colony , Jayana...</td>\n",
       "      <td>1,000 sqft</td>\n",
       "      <td>₹2,00,000</td>\n",
       "      <td>₹ 21,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 BHK In Independent House  For Rent  In Indir...</td>\n",
       "      <td>Independent House, Near Hotel RagavendraExplor...</td>\n",
       "      <td>324 sqft</td>\n",
       "      <td>₹50,000</td>\n",
       "      <td>₹ 10,000 +₹ 200 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House, Near Jayanagar Orthopaedic ...</td>\n",
       "      <td>800 sqft</td>\n",
       "      <td>₹1,20,000</td>\n",
       "      <td>₹ 23,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 BHK Apartment  For Rent  In Gokul Lake View ...</td>\n",
       "      <td>Gokul Lake View Aprtments  110/18, 19th Cross ...</td>\n",
       "      <td>1,532 sqft</td>\n",
       "      <td>₹1,90,000</td>\n",
       "      <td>₹ 25,000 +₹ 4,500 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 BHK Flat  For Rent  In Prithvi Kunj  In Raja...</td>\n",
       "      <td>2nd Block,near Rajajinagar Post OfficeExplore ...</td>\n",
       "      <td>950 sqft</td>\n",
       "      <td>₹3,00,000</td>\n",
       "      <td>₹ 25,000 +₹ 2,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 BHK Apartment  For Rent  In Team Green Wood ...</td>\n",
       "      <td>Team Green Wood Apartment  3rd Main Rd, Indira...</td>\n",
       "      <td>1,648 sqft</td>\n",
       "      <td>₹2,00,000</td>\n",
       "      <td>₹ 46,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1 BHK Apartment  For Rent  In Bangalore Apartm...</td>\n",
       "      <td>Bangalore Apartments  Ganesha templeExplore Ne...</td>\n",
       "      <td>500 sqft</td>\n",
       "      <td>₹1,50,000</td>\n",
       "      <td>₹ 17,000 +₹ 3,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4 BHK In Independent House  For Rent  In Btm 1...</td>\n",
       "      <td>Independent House, near Jayadeva hospitalExplo...</td>\n",
       "      <td>2,250 sqft</td>\n",
       "      <td>₹4,50,000</td>\n",
       "      <td>₹ 45,800 +₹ 1,200 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In 7th C...</td>\n",
       "      <td>Independent House, near Ashoka Pillar, 2nd Blo...</td>\n",
       "      <td>1,050 sqft</td>\n",
       "      <td>₹50,000</td>\n",
       "      <td>₹ 20,500No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House, 20th mainExplore Nearby</td>\n",
       "      <td>2,400 sqft</td>\n",
       "      <td>₹8,00,000</td>\n",
       "      <td>₹ 85,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3 BHK Apartment  For Rent  In Indus Signature ...</td>\n",
       "      <td>Indus Signature  Indus Signature, Eshwara Layo...</td>\n",
       "      <td>1,652 sqft</td>\n",
       "      <td>₹2,00,000</td>\n",
       "      <td>₹ 37,000 +₹ 6,500 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House,  9th Block , near Hotel sid...</td>\n",
       "      <td>850 sqft</td>\n",
       "      <td>₹2,00,000</td>\n",
       "      <td>₹ 20,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House, hotel siddiqueExplore Nearby</td>\n",
       "      <td>550 sqft</td>\n",
       "      <td>₹1,76,000</td>\n",
       "      <td>₹ 16,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2 BHK Apartment  For Rent  In Srinivasa Reside...</td>\n",
       "      <td>Srinivasa Residency  HAL 2nd Stage, near Khivr...</td>\n",
       "      <td>1,050 sqft</td>\n",
       "      <td>₹1,50,000</td>\n",
       "      <td>₹ 24,000 +₹ 2,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1 BHK In Independent House  For Rent  In Tilak...</td>\n",
       "      <td>Independent House, besides Balamuri Ganapathi ...</td>\n",
       "      <td>450 sqft</td>\n",
       "      <td>₹60,000</td>\n",
       "      <td>₹ 9,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3 BHK Flat  For Rent  In Standalone. Building....</td>\n",
       "      <td>BDA shopping complexExplore Nearby</td>\n",
       "      <td>2,400 sqft</td>\n",
       "      <td>₹3,60,000</td>\n",
       "      <td>₹ 36,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3 BHK Apartment  For Rent  In Santa Clara Apar...</td>\n",
       "      <td>Santa Clara Apartments  Marenahalli, Jayanagar...</td>\n",
       "      <td>1,647 sqft</td>\n",
       "      <td>₹3,00,000</td>\n",
       "      <td>₹ 30,000 +₹ 3,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3 BHK Apartment  For Rent  In Phoenix  One Ban...</td>\n",
       "      <td>Phoenix  One Bangalore West  Dr Rajkumar Rd, o...</td>\n",
       "      <td>2,456 sqft</td>\n",
       "      <td>₹11,00,000</td>\n",
       "      <td>₹ 1,35,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2 BHK Flat  For Rent  In Syed Residency In Jay...</td>\n",
       "      <td>Cake Paradise, 5th Main Road, Canara Bank Colo...</td>\n",
       "      <td>1,000 sqft</td>\n",
       "      <td>₹2,30,000</td>\n",
       "      <td>₹ 23,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1 RK In Independent House  For Rent  In Indira...</td>\n",
       "      <td>Independent House, Chinmaya Mission Hospital R...</td>\n",
       "      <td>350 sqft</td>\n",
       "      <td>₹80,000</td>\n",
       "      <td>₹ 20,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Subra...</td>\n",
       "      <td>Independent House, 18TH MAIN, A BLOCK SUBRAMAN...</td>\n",
       "      <td>800 sqft</td>\n",
       "      <td>₹1,70,000</td>\n",
       "      <td>₹ 17,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3 BHK Flat  For Rent  In Jayanagar</td>\n",
       "      <td>Standalone Building, 31st cross 2nd main 7th B...</td>\n",
       "      <td>2,000 sqft</td>\n",
       "      <td>₹3,50,000</td>\n",
       "      <td>₹ 35,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          House Title  \\\n",
       "0   2 BHK Flat  For Rent  In Stanalone Building In...   \n",
       "1                1 RK Flat  For Rent  In Rajajinagar    \n",
       "2   3 BHK Apartment  For Rent  In Santa Clara Apar...   \n",
       "3   2 BHK In Independent House  For Rent  In Jayan...   \n",
       "4   1 BHK In Independent House  For Rent  In Indir...   \n",
       "5   2 BHK In Independent House  For Rent  In Jayan...   \n",
       "6   2 BHK Apartment  For Rent  In Gokul Lake View ...   \n",
       "7   2 BHK Flat  For Rent  In Prithvi Kunj  In Raja...   \n",
       "8   3 BHK Apartment  For Rent  In Team Green Wood ...   \n",
       "9   1 BHK Apartment  For Rent  In Bangalore Apartm...   \n",
       "10  4 BHK In Independent House  For Rent  In Btm 1...   \n",
       "11  2 BHK In Independent House  For Rent  In 7th C...   \n",
       "12  3 BHK In Independent House  For Rent  In Jayan...   \n",
       "13  3 BHK Apartment  For Rent  In Indus Signature ...   \n",
       "14  2 BHK In Independent House  For Rent  In Jayan...   \n",
       "15  2 BHK In Independent House  For Rent  In Jayan...   \n",
       "16  2 BHK Apartment  For Rent  In Srinivasa Reside...   \n",
       "17  1 BHK In Independent House  For Rent  In Tilak...   \n",
       "18  3 BHK Flat  For Rent  In Standalone. Building....   \n",
       "19  3 BHK Apartment  For Rent  In Santa Clara Apar...   \n",
       "20  3 BHK Apartment  For Rent  In Phoenix  One Ban...   \n",
       "21  2 BHK Flat  For Rent  In Syed Residency In Jay...   \n",
       "22  1 RK In Independent House  For Rent  In Indira...   \n",
       "23  2 BHK In Independent House  For Rent  In Subra...   \n",
       "24                3 BHK Flat  For Rent  In Jayanagar    \n",
       "\n",
       "                                             Location        Area  \\\n",
       "0   no 715 2 nd main d block rajaji nagar 2nd stat...  1,400 sqft   \n",
       "1   Standalone Building, 2nd Block, near O.G. Vari...    250 sqft   \n",
       "2   Santa Clara Apartments  3rd Rd Cross Rd, 5T Bl...  1,400 sqft   \n",
       "3   Independent House, D'mart ,RBI Colony , Jayana...  1,000 sqft   \n",
       "4   Independent House, Near Hotel RagavendraExplor...    324 sqft   \n",
       "5   Independent House, Near Jayanagar Orthopaedic ...    800 sqft   \n",
       "6   Gokul Lake View Aprtments  110/18, 19th Cross ...  1,532 sqft   \n",
       "7   2nd Block,near Rajajinagar Post OfficeExplore ...    950 sqft   \n",
       "8   Team Green Wood Apartment  3rd Main Rd, Indira...  1,648 sqft   \n",
       "9   Bangalore Apartments  Ganesha templeExplore Ne...    500 sqft   \n",
       "10  Independent House, near Jayadeva hospitalExplo...  2,250 sqft   \n",
       "11  Independent House, near Ashoka Pillar, 2nd Blo...  1,050 sqft   \n",
       "12         Independent House, 20th mainExplore Nearby  2,400 sqft   \n",
       "13  Indus Signature  Indus Signature, Eshwara Layo...  1,652 sqft   \n",
       "14  Independent House,  9th Block , near Hotel sid...    850 sqft   \n",
       "15    Independent House, hotel siddiqueExplore Nearby    550 sqft   \n",
       "16  Srinivasa Residency  HAL 2nd Stage, near Khivr...  1,050 sqft   \n",
       "17  Independent House, besides Balamuri Ganapathi ...    450 sqft   \n",
       "18                 BDA shopping complexExplore Nearby  2,400 sqft   \n",
       "19  Santa Clara Apartments  Marenahalli, Jayanagar...  1,647 sqft   \n",
       "20  Phoenix  One Bangalore West  Dr Rajkumar Rd, o...  2,456 sqft   \n",
       "21  Cake Paradise, 5th Main Road, Canara Bank Colo...  1,000 sqft   \n",
       "22  Independent House, Chinmaya Mission Hospital R...    350 sqft   \n",
       "23  Independent House, 18TH MAIN, A BLOCK SUBRAMAN...    800 sqft   \n",
       "24  Standalone Building, 31st cross 2nd main 7th B...  2,000 sqft   \n",
       "\n",
       "   Price(Deposite)                             EMI  \n",
       "0        ₹1,00,000     ₹ 17,000 +₹ 500 Maintenance  \n",
       "1          ₹40,000      ₹ 6,000 +₹ 500 Maintenance  \n",
       "2        ₹1,80,000   ₹ 27,000 +₹ 3,000 Maintenance  \n",
       "3        ₹2,00,000    ₹ 21,000No Extra Maintenance  \n",
       "4          ₹50,000     ₹ 10,000 +₹ 200 Maintenance  \n",
       "5        ₹1,20,000    ₹ 23,000No Extra Maintenance  \n",
       "6        ₹1,90,000   ₹ 25,000 +₹ 4,500 Maintenance  \n",
       "7        ₹3,00,000   ₹ 25,000 +₹ 2,000 Maintenance  \n",
       "8        ₹2,00,000    ₹ 46,000No Extra Maintenance  \n",
       "9        ₹1,50,000   ₹ 17,000 +₹ 3,000 Maintenance  \n",
       "10       ₹4,50,000   ₹ 45,800 +₹ 1,200 Maintenance  \n",
       "11         ₹50,000    ₹ 20,500No Extra Maintenance  \n",
       "12       ₹8,00,000    ₹ 85,000No Extra Maintenance  \n",
       "13       ₹2,00,000   ₹ 37,000 +₹ 6,500 Maintenance  \n",
       "14       ₹2,00,000    ₹ 20,000No Extra Maintenance  \n",
       "15       ₹1,76,000    ₹ 16,000No Extra Maintenance  \n",
       "16       ₹1,50,000   ₹ 24,000 +₹ 2,000 Maintenance  \n",
       "17         ₹60,000     ₹ 9,000No Extra Maintenance  \n",
       "18       ₹3,60,000    ₹ 36,000No Extra Maintenance  \n",
       "19       ₹3,00,000   ₹ 30,000 +₹ 3,000 Maintenance  \n",
       "20      ₹11,00,000  ₹ 1,35,000No Extra Maintenance  \n",
       "21       ₹2,30,000    ₹ 23,000No Extra Maintenance  \n",
       "22         ₹80,000    ₹ 20,000No Extra Maintenance  \n",
       "23       ₹1,70,000    ₹ 17,000No Extra Maintenance  \n",
       "24       ₹3,50,000    ₹ 35,000No Extra Maintenance  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame \n",
    "df = pd.DataFrame({\"House Title\":title,\"Location\":location,\"Area\":area,\"Price(Deposite)\":price,\"EMI\":emi})\n",
    "df.to_csv(\"house details from nobroker.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "* i) Restaurant name\n",
    "* ii) Cuisine\n",
    "* iii) Location\n",
    "* iv) Ratings\n",
    "* v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13 13 13 13\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "name = []\n",
    "cuisine = []\n",
    "location = []\n",
    "rating = []\n",
    "image =[]\n",
    "\n",
    "#scraping restaurant names\n",
    "for i in soup.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "    name.append(i.text)\n",
    "    \n",
    "#scraping cuisine\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.text.split(\"|\")[:][1])\n",
    "\n",
    "#scraping location\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "#scraping ratings\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "    \n",
    "#scraping image URL\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    image.append(i['data-src'])\n",
    "    \n",
    "print(len(name),len(cuisine),len(location),len(rating),len(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>Barbecue, North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Multi-Cuisine, North Indian, Italian, Contine...</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>Barbecue, Chinese, Mughlai, North Indian</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian, Oriental</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>Barbecue, North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian, Chinese, Fast Food</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World Cafe</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai, Barbecue</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B Que</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29</td>\n",
       "      <td>North Indian, Chinese, Barbecue</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Glasshouse</td>\n",
       "      <td>Multi-Cuisine, Asian, European, Italian, Nort...</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Restaurant name  \\\n",
       "0                    Castle Barbeque   \n",
       "1                    Jungle Jamboree   \n",
       "2                    Castle Barbeque   \n",
       "3                         Cafe Knosh   \n",
       "4               The Barbeque Company   \n",
       "5                        India Grill   \n",
       "6                     Delhi Barbeque   \n",
       "7   The Monarch - Bar Be Que Village   \n",
       "8                         World Cafe   \n",
       "9                  Indian Grill Room   \n",
       "10                   Mad 4 Bar B Que   \n",
       "11                       Barbeque 29   \n",
       "12                        Glasshouse   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0                               Chinese, North Indian   \n",
       "1              Barbecue, North Indian, Asian, Italian   \n",
       "2                               Chinese, North Indian   \n",
       "3    Multi-Cuisine, North Indian, Italian, Contine...   \n",
       "4            Barbecue, Chinese, Mughlai, North Indian   \n",
       "5                    North Indian, Italian, Oriental    \n",
       "6                              Barbecue, North Indian   \n",
       "7                    North Indian, Chinese, Fast Food   \n",
       "8                  North Indian, Chinese, Continental   \n",
       "9                     North Indian, Mughlai, Barbecue   \n",
       "10                              North Indian, Mughlai   \n",
       "11                    North Indian, Chinese, Barbecue   \n",
       "12   Multi-Cuisine, Asian, European, Italian, Nort...   \n",
       "\n",
       "                                             Location Ratings  \\\n",
       "0                      Connaught Place, Central Delhi     3.5   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi       4   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "4                  Gardens Galleria,Sector 38A, Noida       4   \n",
       "5                Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.9   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad     4.2   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "10                               Sector 29, Faridabad     3.7   \n",
       "11                                     NIT, Faridabad     4.3   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...     4.1   \n",
       "\n",
       "                                            Image URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame \n",
    "df = pd.DataFrame({'Restaurant name':name,'Cuisine':cuisine,'Location':location,'Ratings':rating,'Image URL':image})\n",
    "df.to_csv(\"Restaurants details from dineout.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Write a python program to scrape first 10 product details which include product name , price , Image URL from https://www.bewakoof.com/women-tshirts?ga_q=tshirts ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending the request to the webpage server to get the source coad of the page\n",
    "page = requests.get('https://www.bewakoof.com/women-tshirts?ga_q=tshirts')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content) #download the page content.\n",
    "\n",
    "#creating empty lists\n",
    "name = []\n",
    "price = []\n",
    "image = []\n",
    "\n",
    "#scraping product name\n",
    "for i in soup.find_all('div',class_=\"productCardDetail\"):\n",
    "    name.append(i.text)\n",
    "\n",
    "#scraping price\n",
    "for i in soup.find_all('span',class_=\"discountedPriceText\"):\n",
    "    price.append(i.text)\n",
    "    \n",
    "#scraping image URL\n",
    "for i in soup.find_all('img',class_=\"productImgTag\")[:10]: \n",
    "    image.append(i.get('src')) \n",
    "    \n",
    "print(len(name),len(price),len(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yoga se Hoga Women's Half Sleeve T-Shirt₹ 1997...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/yoga-se-hoga-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wink New Half Sleeve Printed T-Shirt₹ 199799₹1...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/wink-new-half...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bugs On A Pocket Half Sleeve Printed T-Shirt(L...</td>\n",
       "      <td>₹ 249</td>\n",
       "      <td>https://images.bewakoof.com/t320/bugs-on-a-poc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Minnie Mood Half Sleeve Printed T-Shirt (DL)₹ ...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/minnie-mood-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goofy Mickey Pocket Half Sleeve Printed T-Shir...</td>\n",
       "      <td>₹ 799</td>\n",
       "      <td>https://images.bewakoof.com/t320/goofy-mickey-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Black Widow Hyperprint Boyfriend T-Shirt₹ 1997...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/black-widow-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Women's Indigo Printed White T-Shirt₹ 199799₹1...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/beautiful-thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All Day Everyday Half Sleeve T-Shirt₹ 199799₹1...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/all-day-every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Camera Moments Half Sleeve T-Shirt₹ 199799₹179...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/camera-moment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mickey Pop Block Half Sleeve Printed T-Shirt (...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/mickey-pop-bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product_Name  Price  \\\n",
       "0  Yoga se Hoga Women's Half Sleeve T-Shirt₹ 1997...  ₹ 199   \n",
       "1  Wink New Half Sleeve Printed T-Shirt₹ 199799₹1...  ₹ 199   \n",
       "2  Bugs On A Pocket Half Sleeve Printed T-Shirt(L...  ₹ 249   \n",
       "3  Minnie Mood Half Sleeve Printed T-Shirt (DL)₹ ...  ₹ 199   \n",
       "4  Goofy Mickey Pocket Half Sleeve Printed T-Shir...  ₹ 799   \n",
       "5  Black Widow Hyperprint Boyfriend T-Shirt₹ 1997...  ₹ 199   \n",
       "6  Women's Indigo Printed White T-Shirt₹ 199799₹1...  ₹ 199   \n",
       "7  All Day Everyday Half Sleeve T-Shirt₹ 199799₹1...  ₹ 199   \n",
       "8  Camera Moments Half Sleeve T-Shirt₹ 199799₹179...  ₹ 199   \n",
       "9  Mickey Pop Block Half Sleeve Printed T-Shirt (...  ₹ 199   \n",
       "\n",
       "                                           Image_url  \n",
       "0  https://images.bewakoof.com/t320/yoga-se-hoga-...  \n",
       "1  https://images.bewakoof.com/t320/wink-new-half...  \n",
       "2  https://images.bewakoof.com/t320/bugs-on-a-poc...  \n",
       "3  https://images.bewakoof.com/t320/minnie-mood-h...  \n",
       "4  https://images.bewakoof.com/t320/goofy-mickey-...  \n",
       "5  https://images.bewakoof.com/t320/black-widow-h...  \n",
       "6  https://images.bewakoof.com/t320/beautiful-thi...  \n",
       "7  https://images.bewakoof.com/t320/all-day-every...  \n",
       "8  https://images.bewakoof.com/t320/camera-moment...  \n",
       "9  https://images.bewakoof.com/t320/mickey-pop-bl...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame \n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Product_Name':name,'Price':price,'Image_url':image})\n",
    "df.to_csv('top 10 product details from Bewakoof.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
